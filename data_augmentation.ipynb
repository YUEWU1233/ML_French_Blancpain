{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQxSNG_ke_qN",
        "outputId": "c3ce8157-126c-4f28-c851-05d0847027fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ0RpkRzkXQE",
        "outputId": "1833f691-4f5c-4864-f324-3be6304ce2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.12.25)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h2YFbyve66i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "decb3383-5daa-44d7-b1a3-006968274bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "already print 50 records\n",
            "already print 100 records\n",
            "already print 150 records\n",
            "already print 200 records\n",
            "already print 250 records\n",
            "already print 300 records\n",
            "already print 350 records\n",
            "already print 400 records\n",
            "already print 450 records\n",
            "already print 500 records\n",
            "already print 550 records\n",
            "already print 600 records\n",
            "already print 650 records\n",
            "already print 700 records\n",
            "already print 750 records\n",
            "already print 800 records\n",
            "already print 850 records\n",
            "already print 900 records\n",
            "already print 950 records\n",
            "already print 1000 records\n",
            "already print 1050 records\n",
            "already print 1100 records\n",
            "already print 1150 records\n",
            "already print 1200 records\n",
            "already print 1250 records\n",
            "already print 1300 records\n",
            "already print 1350 records\n",
            "already print 1400 records\n",
            "already print 1450 records\n",
            "already print 1500 records\n",
            "already print 1550 records\n",
            "already print 1600 records\n",
            "already print 1650 records\n",
            "already print 1700 records\n",
            "already print 1750 records\n",
            "already print 1800 records\n",
            "already print 1850 records\n",
            "already print 1900 records\n",
            "already print 1950 records\n",
            "already print 2000 records\n",
            "already print 2050 records\n",
            "already print 2100 records\n",
            "already print 2150 records\n",
            "already print 2200 records\n",
            "already print 2250 records\n",
            "already print 2300 records\n",
            "already print 2350 records\n",
            "already print 2400 records\n",
            "already print 2450 records\n",
            "already print 2500 records\n",
            "already print 2550 records\n",
            "already print 2600 records\n",
            "already print 2650 records\n",
            "already print 2700 records\n",
            "already print 2750 records\n",
            "already print 2800 records\n",
            "already print 2850 records\n",
            "already print 2900 records\n",
            "already print 2950 records\n",
            "already print 3000 records\n",
            "already print 3050 records\n",
            "already print 3100 records\n",
            "already print 3150 records\n",
            "already print 3200 records\n",
            "already print 3250 records\n",
            "already print 3300 records\n",
            "already print 3350 records\n",
            "already print 3400 records\n",
            "already print 3450 records\n",
            "already print 3500 records\n",
            "already print 3550 records\n",
            "already print 3600 records\n",
            "already print 3650 records\n",
            "already print 3700 records\n",
            "already print 3750 records\n",
            "already print 3800 records\n",
            "already print 3850 records\n",
            "already print 3900 records\n",
            "already print 3950 records\n",
            "already print 4000 records\n",
            "already print 4050 records\n",
            "already print 4100 records\n",
            "already print 4150 records\n",
            "already print 4200 records\n",
            "already print 4250 records\n",
            "already print 4300 records\n",
            "already print 4350 records\n",
            "already print 4400 records\n",
            "already print 4450 records\n",
            "already print 4500 records\n",
            "already print 4550 records\n",
            "already print 4600 records\n",
            "already print 4650 records\n",
            "already print 4700 records\n",
            "already print 4750 records\n",
            "already print 4800 records\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# load model\n",
        "en_to_fr_model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "fr_to_en_model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
        "tokenizer_en_fr = MarianTokenizer.from_pretrained(en_to_fr_model_name)\n",
        "model_en_fr = MarianMTModel.from_pretrained(en_to_fr_model_name)\n",
        "tokenizer_fr_en = MarianTokenizer.from_pretrained(fr_to_en_model_name)\n",
        "model_fr_en = MarianMTModel.from_pretrained(fr_to_en_model_name)\n",
        "\n",
        "# define traslator\n",
        "def translate(texts, model, tokenizer):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    outputs = model.generate(**inputs)\n",
        "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "# load data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/YUEWU1233/ML_French_Blancpain/main/training_data.csv')\n",
        "\n",
        "# New DataFrame\n",
        "new_data = pd.DataFrame(columns=['id', 'sentence', 'difficulty'])\n",
        "\n",
        "# back translation\n",
        "for index, row in data.iterrows():\n",
        "    # To English\n",
        "    translated_to_en = translate(row['sentence'], model_fr_en, tokenizer_fr_en)[0]\n",
        "    # To French\n",
        "    back_translated_to_fr = translate(translated_to_en, model_en_fr, tokenizer_en_fr)[0]\n",
        "    # Add to new dataset\n",
        "    new_data.loc[index] = [row['id'], back_translated_to_fr, row['difficulty']]\n",
        "\n",
        "    if (index + 1) % 50 == 0:\n",
        "        print(f\"already print {index + 1} records\")\n",
        "\n",
        "# save to new dataset\n",
        "new_data.to_csv('back_translation.csv', index=False)\n",
        "\n",
        "print(\"done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lhxyJ8H2gvC",
        "outputId": "68efa3a5-ef6b-4111-f20a-4620c114493e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "def augment_text(dataframe, augmenter, times=1):\n",
        "    augmented_sentences = []\n",
        "    for _, row in dataframe.iterrows():\n",
        "        for _ in range(times):\n",
        "            augmented_sentence = augmenter.augment(row['sentence'])\n",
        "            augmented_sentences.append({'sentence': augmented_sentence, 'difficulty': row['difficulty']})\n",
        "    return pd.DataFrame(augmented_sentences)\n",
        "\n",
        "# Apply augmentation\n",
        "text_augmenter = naw.SynonymAug(aug_src='wordnet')\n",
        "augmented_data = augment_text(data, text_augmenter, times=1)\n",
        "augmented_data.to_csv('nlpaug.csv', index=False)"
      ],
      "metadata": {
        "id": "ysCw8DeesQIr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}